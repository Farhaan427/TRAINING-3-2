{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMhXe/ZMyYvWz8wLUj64DjV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Farhaan427/TRAINING-3-2/blob/main/Logistic%20Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5CIbUzB-shpW"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b45d57b4"
      },
      "source": [
        "# Task\n",
        "Perform logistic regression on the `heart.csv` dataset, evaluate the model's accuracy, precision, and recall, and identify the most important feature based on the model's coefficients."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fbf68e7d"
      },
      "source": [
        "## Load Dataset\n",
        "\n",
        "### Subtask:\n",
        "Load the provided 'heart.csv' dataset into a pandas DataFrame.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0d62c79e"
      },
      "source": [
        "**Reasoning**:\n",
        "First, I'll import the pandas library to enable data manipulation. Then, I'll load the 'heart.csv' dataset into a DataFrame, display its first 5 rows to verify the data, and show the columns and their data types to understand the dataset's structure.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2f0dbf04",
        "outputId": "cc86cf5b-d6d8-47c5-e282-43556f343f91"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('/content/heart.csv')\n",
        "\n",
        "# Display the first 5 rows\n",
        "print(\"First 5 rows of the DataFrame:\")\n",
        "print(df.head())\n",
        "\n",
        "# Display columns and their data types\n",
        "print(\"\\nDataFrame Info:\")\n",
        "df.info()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First 5 rows of the DataFrame:\n",
            "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
            "0   63    1   3       145   233    1        0      150      0      2.3      0   \n",
            "1   37    1   2       130   250    0        1      187      0      3.5      0   \n",
            "2   41    0   1       130   204    0        0      172      0      1.4      2   \n",
            "3   56    1   1       120   236    0        1      178      0      0.8      2   \n",
            "4   57    0   0       120   354    0        1      163      1      0.6      2   \n",
            "\n",
            "   ca  thal  target  \n",
            "0   0     1       1  \n",
            "1   0     2       1  \n",
            "2   0     2       1  \n",
            "3   0     2       1  \n",
            "4   0     2       1  \n",
            "\n",
            "DataFrame Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 303 entries, 0 to 302\n",
            "Data columns (total 14 columns):\n",
            " #   Column    Non-Null Count  Dtype  \n",
            "---  ------    --------------  -----  \n",
            " 0   age       303 non-null    int64  \n",
            " 1   sex       303 non-null    int64  \n",
            " 2   cp        303 non-null    int64  \n",
            " 3   trestbps  303 non-null    int64  \n",
            " 4   chol      303 non-null    int64  \n",
            " 5   fbs       303 non-null    int64  \n",
            " 6   restecg   303 non-null    int64  \n",
            " 7   thalach   303 non-null    int64  \n",
            " 8   exang     303 non-null    int64  \n",
            " 9   oldpeak   303 non-null    float64\n",
            " 10  slope     303 non-null    int64  \n",
            " 11  ca        303 non-null    int64  \n",
            " 12  thal      303 non-null    int64  \n",
            " 13  target    303 non-null    int64  \n",
            "dtypes: float64(1), int64(13)\n",
            "memory usage: 33.3 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rzQiGUEy2Csg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "G95hS1T3tNIU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7a06cebc"
      },
      "source": [
        "## Prepare Data for Modeling\n",
        "\n",
        "### Subtask:\n",
        "Separate the features (X) and the target variable (y) from the dataset. Then, split the data into training and testing sets to prepare for logistic regression.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0a993002"
      },
      "source": [
        "**Reasoning**:\n",
        "To prepare the data for logistic regression, I will first separate the features (X) and the target variable (y), and then split them into training and testing sets using a 80-20 ratio and a random state for reproducibility.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ca6658d3",
        "outputId": "44c9c3a9-3b46-46ab-c3bd-a77fbbe46317"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Separate features (X) and target variable (y)\n",
        "X = df.drop('target', axis=1)\n",
        "y = df['target']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(f\"X_train shape: {X_train.shape}\")\n",
        "print(f\"X_test shape: {X_test.shape}\")\n",
        "print(f\"y_train shape: {y_train.shape}\")\n",
        "print(f\"y_test shape: {y_test.shape}\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape: (242, 13)\n",
            "X_test shape: (61, 13)\n",
            "y_train shape: (242,)\n",
            "y_test shape: (61,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f73319e5"
      },
      "source": [
        "## Apply Logistic Regression\n",
        "\n",
        "### Subtask:\n",
        "Train a logistic regression model on the prepared training data.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ec7f46b"
      },
      "source": [
        "**Reasoning**:\n",
        "To train the logistic regression model, I will import the `LogisticRegression` class, instantiate it with `random_state=42`, and then fit the model to the training data (`X_train`, `y_train`).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c660abe2",
        "outputId": "0cd10141-6bd9-42a7-e221-3737ceb06bac"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Instantiate the Logistic Regression model\n",
        "model = LogisticRegression(random_state=42)\n",
        "\n",
        "# Fit the model to the training data\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "print(\"Logistic Regression model trained successfully.\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression model trained successfully.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "38b70bec"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous logistic regression model issued a `ConvergenceWarning` because the optimizer reached its iteration limit. To address this, I will scale the features using `StandardScaler` to help with convergence and also increase the `max_iter` parameter in the `LogisticRegression` model.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1653f13b",
        "outputId": "6492f891-698e-4bdd-c95f-d764412eca6d"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Initialize StandardScaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Scale the training and testing data\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Instantiate the Logistic Regression model with increased max_iter\n",
        "# The default solver 'lbfgs' is generally good, and max_iter helps with convergence issues.\n",
        "model = LogisticRegression(random_state=42, max_iter=1000)\n",
        "\n",
        "# Fit the model to the scaled training data\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "print(\"Logistic Regression model trained successfully on scaled data.\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression model trained successfully on scaled data.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d69130f8"
      },
      "source": [
        "## Evaluate Model Performance\n",
        "\n",
        "### Subtask:\n",
        "Calculate and display the accuracy, precision, and recall of the logistic regression model on the test data.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "41611cca"
      },
      "source": [
        "**Reasoning**:\n",
        "To evaluate the model's performance, I will first make predictions on the scaled test data using the trained model. Then, I will import the necessary metrics from `sklearn.metrics` and calculate the accuracy, precision, and recall scores, finally printing them with clear labels.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8d960852",
        "outputId": "60767a2d-963d-40ee-d844-6779cfdbc32d"
      },
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "\n",
        "# Make predictions on the scaled test data\n",
        "y_pred = model.predict(X_test_scaled)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Calculate precision\n",
        "precision = precision_score(y_test, y_pred)\n",
        "\n",
        "# Calculate recall\n",
        "recall = recall_score(y_test, y_pred)\n",
        "\n",
        "# Print the results\n",
        "print(f\"Model Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Model Precision: {precision:.4f}\")\n",
        "print(f\"Model Recall: {recall:.4f}\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy: 0.8525\n",
            "Model Precision: 0.8710\n",
            "Model Recall: 0.8438\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3dda54f9"
      },
      "source": [
        "## Identify Most Important Column\n",
        "\n",
        "### Subtask:\n",
        "Determine and display the most important feature (column) based on the coefficients of the trained logistic regression model.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5dd5bcb0"
      },
      "source": [
        "**Reasoning**:\n",
        "To identify the most important feature, I will access the logistic regression model's coefficients, map them to the original feature names, and then find the feature with the largest absolute coefficient value. I will then display the most important feature and its coefficient.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "81a601d6",
        "outputId": "426b0eb8-1f5a-4330-ccbd-683443ecb25b"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Get the coefficients from the trained model\n",
        "coefficients = model.coef_[0]\n",
        "\n",
        "# Get the feature names from the original X DataFrame\n",
        "feature_names = X.columns\n",
        "\n",
        "# Create a Series to easily map feature names to their coefficients\n",
        "coef_series = pd.Series(coefficients, index=feature_names)\n",
        "\n",
        "# Find the feature with the largest absolute coefficient value\n",
        "most_important_feature = coef_series.abs().idxmax()\n",
        "most_important_coefficient = coef_series[most_important_feature]\n",
        "\n",
        "print(f\"The most important feature is: '{most_important_feature}'\")\n",
        "print(f\"Its coefficient is: {most_important_coefficient:.4f}\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The most important feature is: 'cp'\n",
            "Its coefficient is: 0.8179\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "df40cee1"
      },
      "source": [
        "## Final Task\n",
        "\n",
        "### Subtask:\n",
        "Provide a summary of the logistic regression model's performance metrics and the identified most important feature from the dataset.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cc112026"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Q&A\n",
        "*   **What are the logistic regression model's performance metrics?**\n",
        "    The logistic regression model achieved an accuracy of 0.8525, a precision of 0.8710, and a recall of 0.8438 on the test data.\n",
        "*   **What is the identified most important feature from the dataset based on the model?**\n",
        "    The most important feature identified is 'cp' (chest pain type), with a coefficient of 0.8179.\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "*   The `heart.csv` dataset, containing 303 entries and 14 columns, was successfully loaded and processed.\n",
        "*   The data was split into training (242 samples) and testing (61 samples) sets, with 13 features used for prediction.\n",
        "*   A logistic regression model was trained on scaled data, and the `max_iter` parameter was increased to 1000 to ensure convergence.\n",
        "*   The model demonstrated good predictive capability on the test set, with an accuracy of 85.25%, a precision of 87.10%, and a recall of 84.38%.\n",
        "*   The feature 'cp' (chest pain type) was identified as the most influential predictor of the target variable, possessing the largest absolute coefficient of 0.8179.\n",
        "\n",
        "### Insights or Next Steps\n",
        "*   Further investigation into the 'cp' feature is warranted to understand its exact relationship with heart disease, given its significant impact on the model.\n",
        "*   Consider exploring other advanced classification models or hyperparameter tuning for the current logistic regression model to potentially enhance performance metrics.\n"
      ]
    }
  ]
}